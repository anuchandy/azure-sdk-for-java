package com.azure.ai.inference.usage;

import com.azure.ai.inference.GenAISpanAttributeInjector;
import com.azure.ai.inference.GenAISpanRequestAttributesWriter;
import com.azure.ai.inference.GenAISpanResponseAttributesWriter;
import com.azure.ai.inference.GenAISpanRequestAttributesWriter.GenAIRequestAttributes;
import com.azure.ai.inference.GenAISpanResponseAttributesWriter.GenAIResponseAttributes;
import com.azure.core.http.rest.RequestOptions;
import com.azure.core.util.BinaryData;
import reactor.core.publisher.Flux;

import java.nio.ByteBuffer;
import java.util.function.BiFunction;

// The application type to trace the raw/autogenerated "Protocol" APIs in ChatCompletionClient.
// Application makes this type discoverable to "com.azure.ai.inference.GenAITracerPolicy" via ServiceLoader.
//
public final class GenAIChatCompletionProtocolAPITraceSupport implements com.azure.ai.inference.GenAIChatCompletionTraceSupport {
    @Override
    public GenAISpanAttributeInjector getInjector(ProtocolAPI api) {
        if (api == ProtocolAPI.COMPLETE_WITH_RESPONSE_BINARY_DATA_REQUEST_OPTIONS) {
            return completeWithResponse();
        } else if (api == ProtocolAPI.GET_MODEL_INFO_WITH_RESPONSE_REQUEST_OPTIONS) {
            return getModelInfoWithResponse();
        }
        return null;
    }

    /**
     * Injector for the protocol api - {@link com.azure.ai.inference.ChatCompletionsClient#completeWithResponse(BinaryData, RequestOptions)}
     *
     * @return the injector.
     */
    private GenAISpanAttributeInjector completeWithResponse() {
        return new GenAISpanAttributeInjector() {

            @Override
            public BiFunction<Flux<ByteBuffer>, GenAISpanRequestAttributesWriter, Flux<ByteBuffer>> getRequestInjector() {

                return (Flux<ByteBuffer> contentChunks, GenAISpanRequestAttributesWriter writer) -> {
                    //
                    // Example-1: (App stuffed Context at the time of Protocol API invocation).
                    //      final Context callCxt = writer.getCallContext();
                    //      final Double temperature = callCxt.getData("temperature");
                    //      final int maxTokens = callCxt.getData("maxTokens");
                    //      final int topP = callCxt.getData("topP");
                    //      final String model = "gpt-o";
                    //      final GenAIRequestAttributes attributes = new GenAIRequestAttributes();
                    //      attributes.setMaxTokens(maxTokens).setTemperature(temperature).setTopP(1).setModelId(model);
                    //      writer.write(attributes);
                    //      return contentChunks;
                    //
                    // Example-2: Decode "contentChunks" to extract 'modelId', 'temperature', 'maxToken', 'topP' and write
                    return decodeChatCompletionContentAndWrite(contentChunks, writer);
                };

            }

            @Override
            public BiFunction<Flux<ByteBuffer>, GenAISpanResponseAttributesWriter, Flux<ByteBuffer>> getResponseInjector() {
                return (Flux<ByteBuffer> contentChunks, GenAISpanResponseAttributesWriter writer) -> {
                    return decodeChatCompletionContentAndWrite(contentChunks, writer);
                };
            }
        };
    }


    /**
     * Injector for the protocol api - 'com.azure.ai.inference.ChatCompletionsClient#getModelInfoWithResponse(RequestOptions)'.
     *
     * @return the injector.
     */
    private GenAISpanAttributeInjector getModelInfoWithResponse() {
        return new GenAISpanAttributeInjector() {
            @Override
            public BiFunction<Flux<ByteBuffer>, GenAISpanRequestAttributesWriter, Flux<ByteBuffer>> getRequestInjector() {
                return null;
            }

            @Override
            public BiFunction<Flux<ByteBuffer>, GenAISpanResponseAttributesWriter, Flux<ByteBuffer>> getResponseInjector() {
                return null;
            }
        };
    }

    //<editor-fold desc="Private util methods">

    private Flux<ByteBuffer> decodeChatCompletionContentAndWrite(Flux<ByteBuffer> chunks,
        GenAISpanRequestAttributesWriter writer) {
        final ChatCompletionInDecoder decoder = new ChatCompletionInDecoder(writer);
        return chunks.map(chunk -> {
            final ByteBuffer chunkCopy = (chunk.isDirect())
                ? ByteBuffer.allocateDirect(chunk.capacity())
                : ByteBuffer.allocate(chunk.capacity());
            final ByteBuffer rob = chunk.asReadOnlyBuffer();
            rob.flip();
            chunkCopy.put(rob);
            decoder.onNext(rob);
            return chunkCopy;
        }).doOnComplete(decoder::onComplete);
    }

    private static final class ChatCompletionInDecoder {
        private final GenAISpanRequestAttributesWriter writer;

        ChatCompletionInDecoder(GenAISpanRequestAttributesWriter writer) {
            this.writer = writer;
        }

        void onNext(ByteBuffer chunk) {
            //
        }

        void onComplete() {
            final GenAIRequestAttributes spanAttributes = new GenAIRequestAttributes();
            spanAttributes
                .setTemperature(72)
                .setMaxTokens(2)
                .setTopP(3)
                .setModelId("123");
            writer.write(spanAttributes);
        }
    }

    private Flux<ByteBuffer> decodeChatCompletionContentAndWrite(Flux<ByteBuffer> chunks,
        GenAISpanResponseAttributesWriter writer) {
        final ChatCompletionOutDecoder decoder = new ChatCompletionOutDecoder(writer);
        return chunks.map(chunk -> {
            final ByteBuffer chunkCopy = (chunk.isDirect())
                ? ByteBuffer.allocateDirect(chunk.capacity())
                : ByteBuffer.allocate(chunk.capacity());
            final ByteBuffer rob = chunk.asReadOnlyBuffer();
            rob.flip();
            chunkCopy.put(rob);
            decoder.onNext(rob);
            return chunkCopy;
        }).doOnComplete(decoder::onComplete);
    }

    private static final class ChatCompletionOutDecoder {
        private final GenAISpanResponseAttributesWriter writer;

        ChatCompletionOutDecoder(GenAISpanResponseAttributesWriter writer) {
            this.writer = writer;
        }

        void onNext(ByteBuffer chunk) {
            //
        }

        void onComplete() {
            final GenAIResponseAttributes spanAttributes = new GenAIResponseAttributes();
            spanAttributes
                .setCompletionTokens(2)
                .setPromptTokens(4)
                .setModel("gpt-o")
                .setFinishReasons("[tool_call, stop]");
            writer.write(spanAttributes);
        }
    }

    //</editor-fold>
}
